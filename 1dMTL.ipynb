{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e52d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten, Concatenate\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "#combined RPSP\n",
    "combined_input = Input((12,1,1))\n",
    "combined_inputt = Reshape([1,12],name='Combined_Input')(combined_input)\n",
    "x1 = combined_inputt\n",
    "x1 = Dense(units=1, activation='tanh', name=\"Densecomb\")(x1)\n",
    "hidden_layers1 = 2\n",
    "for i in range(hidden_layers1-1):\n",
    "    x1 = Dense(units=1, activation='tanh', name=\"Dense1{}\".format(i))(x1)\n",
    "    #x = Dropout(0.2, name='Drop{}'.format(i))(x)\n",
    "dropped1 = x1\n",
    "comb_featureR = Dense(units=2, name=\"Output_comb_feature1\")(dropped1)\n",
    "comb_featureR1 = Reshape([2], name='Remove_Dim1')(comb_featureR)\n",
    "#only RP\n",
    "onlyRP_input = Input((8,1,1))\n",
    "onlyRP_inputt = Reshape([1,8],name='OnlyRP_input')(onlyRP_input)\n",
    "x2 = onlyRP_inputt\n",
    "x2 = Dense(units=1, activation='tanh', name=\"DenseRP\")(x2)\n",
    "hidden_layers2 = 2\n",
    "for i in range(hidden_layers2-1):\n",
    "    x2 = Dense(units=1, activation='tanh', name=\"Dense2{}\".format(i))(x2)\n",
    "    #x = Dropout(0.2, name='Drop{}'.format(i))(x)\n",
    "dropped2 = x2\n",
    "comb_feature2 = Dense(units=2, name=\"Output_RP_feature\")(dropped2)\n",
    "comb_featureR2 = Reshape([2], name='Remove_Dim2')(comb_feature2)\n",
    "#only SP\n",
    "onlySP_input = Input((4,1,1))\n",
    "onlySP_inputt = Reshape([1,4],name='OnlySP_input')(onlySP_input)\n",
    "x3 = onlySP_inputt\n",
    "x3 = Dense(units=1, activation='tanh', name=\"DenseSP\")(x3)\n",
    "hidden_layers3 = 2\n",
    "for i in range(hidden_layers3-1):\n",
    "    x3 = Dense(units=1, activation='tanh', name=\"Dense3{}\".format(i))(x3)\n",
    "    #x = Dropout(0.2, name='Drop{}'.format(i))(x)\n",
    "dropped3 = x3\n",
    "comb_feature3 = Dense(units=2, name=\"Output_SP_feature\")(dropped3)\n",
    "comb_featureR3 = Reshape([2], name='Remove_Dim3')(comb_feature3)\n",
    "#adding four components of utilities\n",
    "final_utilities = Add(name=\"New_Utility_functions\")([comb_featureR1,comb_featureR2, comb_featureR3])\n",
    "logits = Activation('softmax', name='Choice')(final_utilities)\n",
    "model = Model(inputs=[combined_input,onlyRP_input, onlySP_input], outputs=logits)\n",
    "model.summary()\n",
    "W11 = model.trainable_variables[6]\n",
    "W12 = model.trainable_variables[7]\n",
    "W13 = model.trainable_variables[12]\n",
    "W14 = model.trainable_variables[13]\n",
    "def custom_loss(weight11, weight12,weight13,weight14):\n",
    "    def _custom_loss():\n",
    "        loss = (10**(-20)) * (tf.sqrt(tf.reduce_sum(tf.square(weight11))+tf.reduce_sum(tf.square(weight12))+ tf.reduce_sum(tf.square(weight13))+tf.reduce_sum(tf.square(weight14))))\n",
    "        return loss\n",
    "    return _custom_loss\n",
    "W21 = model.trainable_variables[10]\n",
    "W22 = model.trainable_variables[11]\n",
    "W23 = model.trainable_variables[16]\n",
    "W24 = model.trainable_variables[17]\n",
    "def custom_loss1(weight21, weight22,weight23,weight24):\n",
    "    def _custom_loss1():\n",
    "        loss1 = (10**(-20)) * (tf.sqrt(tf.reduce_sum(tf.square(weight21))+tf.reduce_sum(tf.square(weight22))+ tf.reduce_sum(tf.square(weight23))+tf.reduce_sum(tf.square(weight24))))\n",
    "        return loss1\n",
    "    return _custom_loss1\n",
    "W31 = model.trainable_variables[8]\n",
    "W32 = model.trainable_variables[9]\n",
    "W33 = model.trainable_variables[14]\n",
    "W34 = model.trainable_variables[15]\n",
    "W41 = W21 - W31\n",
    "W42 = W22 - W32\n",
    "W43 = W23 - W33\n",
    "W44 = W24 - W34\n",
    "def custom_loss2(weight41,weight42,weight43,weight44):\n",
    "    def _custom_loss2():\n",
    "        loss2 = (10**(-20)) * (tf.sqrt(tf.reduce_sum(tf.square(weight42))+ tf.reduce_sum(tf.square(weight43))+tf.reduce_sum(tf.square(weight44))))\n",
    "        return loss2\n",
    "    return _custom_loss2\n",
    "model.add_loss(custom_loss(W11, W12,W13,W14 ))\n",
    "model.add_loss(custom_loss1(W21, W22,W23, W24))\n",
    "model.add_loss(custom_loss2(W41, W42,W43, W44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ad0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shelve\n",
    "import _pickle as pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import np_utils\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "#choicedata\n",
    "choice_data = np.load('/home/rahul/interaction2/ITTATTnterMTL/1/1/MNLneural_choice.npy')\n",
    "train_labels = Reshape([2]) (choice_data)\n",
    "#combineddata\n",
    "combined_data = np.load('/home/rahul/interaction2/ITTATTnterMTL/1/1/MNLneural_comb.npy')\n",
    "combined_data  = np.delete(combined_data, -1, axis = 2)\n",
    "def normalize(data):\n",
    "    return (data-data.mean(axis=0))/(data.std(axis=0))\n",
    "combined_data = normalize(combined_data )\n",
    "#RPdata\n",
    "RP_data = np.load('/home/rahul/interaction2/ITTATTnterMTL/1/1/MNLneural_RP.npy')\n",
    "RP_data = np.delete(RP_data, -1, axis = 2)\n",
    "def normalize(data):\n",
    "    return (data-data.mean(axis=0))/(data.std(axis=0))\n",
    "RP_data = normalize(RP_data)\n",
    "#SP utilities\n",
    "SP_data = np.load('/home/rahul/interaction2/ITTATTnterMTL/1/1/MNLneural_SP.npy')\n",
    "SP_data = np.delete(SP_data, -1, axis = 2)\n",
    "def normalize(data):\n",
    "    return (data-data.mean(axis=0))/(data.std(axis=0))\n",
    "SP_data = normalize(SP_data)\n",
    "#estimation\n",
    "#callback = EarlyStopping(monitor ='loss', min_delta=0.000004, patience =15,restore_best_weights=True)\n",
    "model.compile(optimizer = Adam(clipnorm = 50.), metrics = [tf.keras.metrics.CategoricalAccuracy()], loss = 'categorical_crossentropy')\n",
    "history = model.fit([combined_data,RP_data,SP_data],train_labels, epochs = 2000, batch_size = 50, verbose = 2)\n",
    "evaluation = model.evaluate([combined_data,RP_data,SP_data],train_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50b027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
